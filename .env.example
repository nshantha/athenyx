# Neo4j Connection
NEO4J_URI=bolt://localhost:7687 # Use service name from docker-compose
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=pleasechangethispassword # CHANGE THIS! Matches docker-compose

# OpenAI API Key
OPENAI_API_KEY="sk-..."

# Embedding Model (Example: OpenAI's text-embedding-3-small)
OPENAI_EMBEDDING_MODEL="text-embedding-3-small"
EMBEDDING_DIMENSIONS=1536

# LLM Model for Generation (Example: GPT-4o-Mini)
OPENAI_LLM_MODEL="gpt-4o-mini"

# Web Search Tool (Tavily)
TAVILY_API_KEY="tvly-..."

# Ingestion Settings
# Repository to clone and index (example)
INGEST_REPO_URL="https://github.com/GoogleCloudPlatform/microservices-demo.git"
# Specify branch if needed
# INGEST_REPO_BRANCH="master"
# Target languages and file extensions for parsing
INGEST_TARGET_EXTENSIONS=".py" # Comma-separated if multiple: .py,.java

# Streamlit UI Backend URL
# This should point to where the backend service is accessible FROM the frontend container
# In docker-compose, this is typically http://<backend_service_name>:<port>
BACKEND_API_URL=http://localhost:8000

# Logging Level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO